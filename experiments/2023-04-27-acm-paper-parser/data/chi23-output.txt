Title: Cognition-Oriented Facilitation and Guidelines for Collaborative Problem-Solving Online and Face-to-Face: An in-Depth Examination of Format and Facilitation Influence on Problem-Solving Performance
Abstract: During the Covid-19 pandemic, more guidelines were created to teach people how to facilitate meetings online, but few were designed from a cognition-oriented perspective. Additionally, solving complex problems is essential in many occupations. However, the influence of online and face-to-face discussion formats on the performance in complex problem-solving tasks is unclear, even though remote working has become common over the past several few years. Hence, this study aims to answer two research questions: (a) Does problem-solving performance differ between online and face-to-face meetings? and (b) Does facilitation improve problem-solving performance when different formats are used? We conducted experiments with 40 groups using a 2 × 2 factorial design, which were controlled for both facilitation and format. Each group comprised two randomly selected participants, and each problem-solving discussion lasted between 1.5–2 h. The obtained evidence showed that format can influence the performance of balancing intercorrelated factors in a complex scenario, but it does not affect the performance of achieving a predefined goal. Instead, it we found that facilitation is helpful for achieving a predefined goal. Based on the results obtained, we propose future design directions for problem-solving centric computer-supported cooperative work systems from a cognition-oriented perspective.
URL: https://doi.org/10.1145/3544548.3581112

Title: Cyborg Assemblages: How Autistic Adults Construct Sociotechnical Networks to Support Cognitive Function
Abstract: Autism has become a popular context for accessible technology researchers, yet a majority of HCI projects for autism and ADHD do not engage in participatory methods or otherwise involve disabled stakeholders in the project and research design. Prior inquiry has identified executive function as a common difficulty for which technologies may provide novel benefits. In this study, we explore how autistic adults currently use technologies, broadly defined, to augment executive function and support themselves in day-to-day tasks. We collect qualitative data from narratives elicited during informal asynchronous interviews to conduct a digital ethnomethodology. Following from principles of Design Justice, crip technoscience, and cyborg assemblage theory, we investigate how autistic adults articulate their own sociotechnical environments into technologically mediated assemblages of executive function and interpersonal webs of care. These patterns of sociotechnical formation inform future work in research and design for tools that can mediate executive function for all users.
URL: https://doi.org/10.1145/3544548.3581556

Title: Empathic Accuracy and Mental Effort During Remote Assessments of Emotions
Abstract: Observing users in remote settings is unfavorable because it adds filters altering the information that underlie judgement. Still, the COVID pandemic led to an unprecedented popularity of remote user experience tests. In this work, we revisited the question, which information is most important for evaluators to assess users’ emotions successfully and efficiently. In an online study, we asked N=55 participants to assess users’ emotions from short videos of 30 interaction situations. As independent variable, we manipulated the combination of the information channels video of users, video of the interactive technology, and audio within subjects. Our findings indicate that empathic accuracy is highest and mental effort is lowest when all stimuli are present. Surprisingly, empathic accuracy was lowest and mental effort highest, when only video of users was available. We discuss these findings in the light of emotion literature focusing on persons’ facial expressions and derive practical implications for remote observations.
URL: https://doi.org/10.1145/3544548.3580824

Title: It is Okay to Be Distracted: How Real-Time Transcriptions Facilitate Online Meeting with Distraction
Abstract: Online meetings are indispensable in collaborative remote work environments, but they are vulnerable to distractions due to their distributed and location-agnostic nature. While distraction often leads to a decrease in online meeting quality due to loss of engagement and context, natural multitasking has positive tradeoff effects, such as increased productivity within a given time unit. In this study, we investigate the impact of real-time transcriptions (i.e., full-transcripts, summaries, and keywords) as a solution to help facilitate online meetings during distracting moments while still preserving multitasking behaviors. Through two rounds of controlled user studies, we qualitatively and quantitatively show that people can better catch up with the meeting flow and feel less interfered with when using real-time transcriptions. The benefits of real-time transcriptions were more pronounced after distracting activities. Furthermore, we reveal additional impacts of real-time transcriptions (e.g., supporting recalling contents) and suggest design implications for future online meeting platforms where these could be adaptively provided to users with different purposes.
URL: https://doi.org/10.1145/3544548.3580742

Title: Understanding Perception of Human Augmentation: A Mixed-Method Study
Abstract: Technologies that help users overcome their limitations and integrate with the human body are often termed “human augmentations”. Such technologies are now available on the consumer market, potentially supporting people in their everyday activities. To date, there is no systematic understanding of the perception of human augmentations yet. To address this gap and build an understanding of how to design positive experiences with human augmentations, we conducted a mixed-method study of the perception of augmented humans (AHs). We conducted two scenario-based studies: interviews (n = 16) and an online study (n = 506) with participants from four countries. The scenarios include one out of three augmentation categories (sensory, motor, and cognitive) and specify if the augmented person has a disability or not. Overall, results show that the type of augmentation and disability impacted user attitudes towards AHs. We derive design dimensions for creating technological augmentations for a diverse and global audience.
URL: https://doi.org/10.1145/3544548.3581485

Title: “We Need to Do More... I Need to Do More”: Augmenting Digital Media Consumption via Critical Reflection to Increase Compassion and Promote Prosocial Attitudes and Behaviors
Abstract: Much HCI research on prompting prosocial behaviors focuses on methods for increasing empathy. However, increased empathy may have unintended negative consequences. Our work offers an alternative solution that encourages critical reflection for nurturing compassion, which involves motivation and action to help others. In a between-subject experiment, participants (N=60) viewed a climate change documentary while receiving no prompts (CON), reflective prompts to focus on their emotions (RE) or surprises (RS). State compassion, critical reflection, and motivation to act or learn were measured at the end of the session (post-video) and two weeks later (follow-up). Despite participants’ condition not affecting compassion, critical reflection was positively correlated with post-video state compassion. RE and RS participants demonstrated deeper reflection and reported higher motivation to learn post-video, and more prosocial behavioral changes during follow-up. RS participants reported better follow-up recall than RE participants. We conclude by discussing implications on designing technology to support compassion and longer-term critical reflection.
URL: https://doi.org/10.1145/3544548.3581355

Title: A Study of Editor Features in a Creative Coding Classroom
Abstract: Creative coding is a rapidly expanding domain for both artistic expression and computational education. Numerous libraries and IDEs support creative coding, however there has been little consideration of how the environments themselves might be designed to serve these twin goals. To investigate this gap, we implemented and used an experimental editor to teach a sequence of college and high-school creative coding courses. In the first year, we conducted a log analysis of student work (n=39) and surveys regarding prospective features (n=25). These guided our implementation of common enhancements (e.g. color pickers) as well as uncommon ones (e.g. bidirectional shape editing). In the second year, we studied the effects of these features through logging (n=39+) and survey (n=23) studies. Reflecting on the results, we identify opportunities to improve creativity- and novice-focused IDEs and highlight tensions in their design—as in tools that augment artistry or efficiency but may be perceived as hindering learning.
URL: https://doi.org/10.1145/3544548.3580683

Title: De-Stijl: Facilitating Graphics Design with Interactive 2D Color Palette Recommendation
Abstract: Selecting a proper color palette is critical in crafting a high-quality graphic design to gain visibility and communicate ideas effectively. To facilitate this process, we propose De-Stijl, an intelligent and interactive color authoring tool to assist novice designers in crafting harmonic color palettes, achieving quick design iterations, and fulfilling design constraints. Through De-Stijl, we contribute a novel 2D color palette concept that allows users to intuitively perceive color designs in context with their proportions and proximities. Further, De-Stijl implements a holistic color authoring system that supports 2D palette extraction, theme-aware and spatial-sensitive color recommendation, and automatic graphical elements (re)colorization. We evaluated De-Stijl through an in-lab user study by comparing the system with existing industry standard tools, followed by in-depth user interviews. Quantitative and qualitative results demonstrate that De-Stijl is effective in assisting novice design practitioners to quickly colorize graphic designs and easily deliver several alternatives.
URL: https://doi.org/10.1145/3544548.3581070

Title: Drawing Transforms: A Unifying Interaction Primitive to Procedurally Manipulate Graphics across Style, Space, and Time
Abstract: Procedural functionality enables visual creators to rapidly edit, explore alternatives, and fine-tune artwork in many domains including illustration, motion graphics, and interactive animation. Symbolic procedural tools, such as textual programming languages, are highly expressive but often limit directly manipulating concrete artwork; whereas direct manipulation tools support some procedural expression but limit creators to pre-defined behaviors and inputs. Inspired by visions of using geometric input to create procedural relationships, we identify an opportunity to use vector geometry from artwork to specify expressive user-defined procedural functions. We present Drawing Transforms (DTs), a technique that enables the use of any drawing to procedurally transform the stylistic, spatial, and temporal properties of target artwork. We apply DTs in a prototype motion graphics system to author continuous and discrete transformations, modify multiple elements in a composition simultaneously, create animations, and control fine-grained procedural instantiation. We discuss how DTs can unify procedural authoring through direct manipulation across visual media domains.
URL: https://doi.org/10.1145/3544548.3580642

Title: Lyric App Framework: A Web-Based Framework for Developing Interactive Lyric-Driven Musical Applications
Abstract: Lyric videos have become a popular medium to convey lyrical content to listeners, but they present the same content whenever they are played and cannot adapt to listeners’ preferences. Lyric apps, as we name them, are a new form of lyric-driven visual art that can render different lyrical content depending on user interaction and address the limitations of static media. To open up this novel design space for programmers and musicians, we present Lyric App Framework, a web-based framework for building interactive graphical applications that play musical pieces and show lyrics synchronized with playback. We designed the framework to provide a streamlined development experience for building production-ready lyric apps with creative coding libraries of choice. We held programming contests twice and collected 52 examples of lyric apps, enabling us to reveal eight representative categories, confirm the framework’s effectiveness, and report lessons learned.
URL: https://doi.org/10.1145/3544548.3580931

Title: Rapsai: Accelerating Machine Learning Prototyping of Multimedia Applications through Visual Programming
Abstract: In recent years, there has been a proliferation of multimedia applications that leverage machine learning (ML) for interactive experiences. Prototyping ML-based applications is, however, still challenging, given complex workflows that are not ideal for design and experimentation. To better understand these challenges, we conducted a formative study with seven ML practitioners to gather insights about common ML evaluation workflows. The study helped us derive six design goals, which informed Rapsai1, a visual programming platform for rapid and iterative development of end-to-end ML-based multimedia applications. Rapsai features a node-graph editor to facilitate interactive characterization and visualization of ML model performance. Rapsai streamlines end-to-end prototyping with interactive data augmentation and model comparison capabilities in its no-coding environment. Our evaluation of Rapsai in four real-world case studies (N=15) suggests that practitioners can accelerate their workflow, make more informed decisions, analyze strengths and weaknesses, and holistically evaluate model behavior with real-world input.
URL: https://doi.org/10.1145/3544548.3581338

Title: Understanding Version Control as Material Interaction with Quickpose
Abstract: Whether a programmer with code or a potter with clay, practitioners engage in an ongoing process of working and reasoning with materials. Existing discussions in HCI have provided rich accounts of these practices and processes, which we synthesize into three themes: (1) reciprocal discovery of goals and materials, (2) local knowledge of materials, and (3) annotation for holistic interpretation. We then apply these design principles generatively to the domain of version control to present Quickpose: a version control system for creative coding. In an in-situ, longitudinal study of Quickpose guided by our themes, we collected usage data, version history, and interviews. Our study explored our participants’ material interaction behaviors and the initial promise of our proposed measures for recognizing these behaviors. Quickpose is an exploration of version control as material interaction, using existing discussions to inform domain-specific concepts, measures, and designs for version control systems.
URL: https://doi.org/10.1145/3544548.3581394

Title: Communicating Consequences: Visual Narratives, Abstraction, and Polysemy in Rural Bangladesh
Abstract: Information communication and visualization practices reflect two centuries of developments of conventions and best practices which may not be reflective of global audiences’ methods for conveying information. Contrasting between rural traditional visual culture and contemporary HCI and data-visualization, we argue that an understanding of traditional practices for information visualization is required for building rich data-narratives and making data-driven systems more accessible and culturally situated. Our ten-month ethnographic study investigates how rural Bangladeshi communities construct narratives through visual media. 1 Our observation, interviews, and FGDs (n=54) expose how participants convey risk management, decision-making, and monetary management practices to their peers. We find that villagers used a rich network of polysemic symbols and abstractions to manifest subjectivity, factuality, consequence, situatedness, and uncertainty; varied visual attributes for constructing narratives; and emphasized material relations among components in visuals. These findings inform the design of future systems for decision support in a culturally situated manner.
URL: https://doi.org/10.1145/3544548.3581149

Title: GeoCamera: Telling Stories in Geographic Visualizations with Camera Movements
Abstract: In geographic data videos, camera movements are frequently used and combined to present information from multiple perspectives. However, creating and editing camera movements requires significant time and professional skills. This work aims to lower the barrier of crafting diverse camera movements for geographic data videos. First, we analyze a corpus of 66 geographic data videos and derive a design space of camera movements with a dimension for geospatial targets and one for narrative purposes. Based on the design space, we propose a set of adaptive camera shots and further develop an interactive tool called GeoCamera. This interactive tool allows users to flexibly design camera movements for geographic visualizations. We verify the expressiveness of our tool through case studies and evaluate its usability with a user study. The participants find that the tool facilitates the design of camera movements.
URL: https://doi.org/10.1145/3544548.3581470

Title: Is It the End? Guidelines for Cinematic Endings in Data Videos
Abstract: Data videos are becoming increasingly popular in society and academia. Yet little is known about how to create endings that strengthen a lasting impression and persuasion. To fulfill the gap, this work aims to develop guidelines for data video endings by drawing inspiration from cinematic arts. To contextualize cinematic endings in data videos, 111 film endings and 105 data video endings are first analyzed to identify four common styles using the framework of ending punctuation marks. &nbsp;We conducted expert interviews (N=11) and formulated 20 guidelines for creating cinematic endings in data videos. To validate our guidelines, we conducted a user study where 24 participants were invited to design endings with and without our guidelines, which are evaluated by experts and the general public. The participants praise the clarity and usability of the guidelines, and results show that the endings with guidelines are perceived to be more understandable, impressive, and reflective.
URL: https://doi.org/10.1145/3544548.3580701

Title: NetworkNarratives: Data Tours for Visual Network Exploration and Analysis
Abstract: This paper introduces semi-automatic data tours to aid the exploration of complex networks. Exploring networks requires significant effort and expertise and can be time-consuming and challenging. Distinct from guidance and recommender systems for visual analytics, we provide a set of goal-oriented tours for network overview, ego-network analysis, community exploration, and other tasks. Based on interviews with five network analysts, we developed a user interface (NetworkNarratives) and 10 example tours. The interface allows analysts to navigate an interactive slideshow featuring facts about the network using visualizations and textual annotations. On each slide, an analyst can freely explore the network and specify nodes, links, or subgraphs as seed elements for follow-up tours. Two studies, comprising eight expert and 14 novice analysts, show that data tours reduce exploration effort, support learning about network exploration, and can aid the dissemination of analysis results. NetworkNarratives is available online, together with detailed illustrations for each tour.
URL: https://doi.org/10.1145/3544548.3581452

Title: Notable: On-the-Fly Assistant for Data Storytelling in Computational Notebooks
Abstract: Computational notebooks are widely used for data analysis. Their interleaved displays of code and execution results (e.g., visualizations) are welcomed since they enable iterative analysis and preserve the exploration process. However, the communication of data findings remains challenging in computational notebooks. Users have to carefully identify useful findings from useless ones, document them with texts and visual embellishments, and then organize them in different tools. Such workflow greatly increases their workload, according to our interviews with practitioners. To address the challenge, we designed Notable to offer on-the-fly assistance for data storytelling in computational notebooks. It provides intelligent support to minimize the work of documenting and organizing data findings and diminishes the cost of switching between data exploration and storytelling. To evaluate Notable, we conducted a user study with 12 data workers. The feedback from user study participants verifies its effectiveness and usability.
URL: https://doi.org/10.1145/3544548.3580965

Title: When Do Data Visualizations Persuade? The Impact of Prior Attitudes on Learning about Correlations from Scatterplot Visualizations
Abstract: Data visualizations are vital to scientific communication on critical issues such as public health, climate change, and socioeconomic policy. They are often designed not just to inform, but to persuade people to make consequential decisions (e.g., to get vaccinated). Are such visualizations persuasive, especially when audiences have beliefs and attitudes that the data contradict? In this paper we examine the impact of existing attitudes (e.g., positive or negative attitudes toward COVID-19 vaccination) on changes in beliefs about statistical correlations when viewing scatterplot visualizations with different representations of statistical uncertainty. We find that strong prior attitudes are associated with smaller belief changes when presented with data that contradicts existing views, and that visual uncertainty representations may amplify this effect. Finally, even when participants’ beliefs about correlations shifted their attitudes remained unchanged, highlighting the need for further research on whether data visualizations can drive longer-term changes in views and behavior.
URL: https://doi.org/10.1145/3544548.3581330

Title: Envisioning and Understanding Orientations to Introspective AI: Exploring a Design Space with Meta.Aware
Abstract: Introspection is the practice of looking inward for ongoing self-examination. It involves considering one's past experiences and asking questions about the present and future. Our work investigates how AI could open new possibilities for supporting introspective experiences. Adopting a design fiction approach, we created a fictional company called Meta.Aware to contextualize 4 different Introspective AI product concepts in the form of video sketches. We used the Meta.Aware platform to conduct interviews with 17 participants, using the 4 concept videos as prompts for discussion. Participants had a range of reactions related to perceived benefits and tensions in this emerging design space. We interpret these results to outline future design directions for mobilizing AI as a resource to support introspective experiences over time, as well as to reflect on issues and dilemmas bound to this emerging design space.
URL: https://doi.org/10.1145/3544548.3581336

Title: Promoting Inclusiveness and Fairness through NFTs: The Case of Student-Athletes and NILs
Abstract: Recent regulatory changes have enabled NCAA student-athletes to profit from their name, image, and likeness (NIL), departing from previous policies requiring those athletes to maintain their amateur status. However, despite the changes, it is unlikely that all the approximately 500,000 NCAA student-athletes will profit from NIL contracts. Within this context, we study how to design a fair and inclusive solution that may help all student-athletes secure NIL financial resources. Following a design science approach, we define design requirements after interviewing student-athletes. Subsequently, we derive three design principles: inclusiveness, fairness, and transparency. Thereafter, we suggest a blockchain-based artifact that satisfies all design principles. Our idea lies in designing collectibles as non-fungible tokens (NFTs) that pay different royalties whenever a transaction (purchase or exchange) happens in different markets (primary or secondary). Finally, we evaluate our solution by discussing its features with current student-athletes.
URL: https://doi.org/10.1145/3544548.3580732

Title: Research Products at Scale: Learnings from Designing Devices in Multiples of Ones, Tens, Hundreds and Thousands
Abstract: In this paper, I argue that scale is an important quality of research products [32] and reflect upon the lessons learnt from designing and producing research products at scales ranging from one-offs to those reproduced in thousands. I describe details from a body of research completed by our studio over twenty years by examining four research projects that were designed, developed, and manufactured at four distinct levels of scale. I draw out details from these projects that have not previously been reported and discuss the methodological implications of growth not just for design and production, but also for strategies for engaging with participants. In addition, I discuss particular features of research products produced at the four levels of scale and describe the benefits and trade-offs of producing research products at different scales.
URL: https://doi.org/10.1145/3544548.3581540

Title: The Entoptic Field Camera as Metaphor-Driven Research-through-Design with AI Technologies
Abstract: Artificial intelligence (AI) technologies are widely deployed in smartphone photography; and prompt-based image synthesis models have rapidly become commonplace. In this paper, we describe a Research-through-Design (RtD) project which explores this shift in the means and modes of image production via the creation and use of the Entoptic Field Camera. Entoptic phenomena usually refer to perceptions of floaters or bright blue dots stemming from the physiological interplay of the eye and brain. We use the term entoptic as a metaphor to investigate how the material interplay of data and models in AI technologies shapes human experiences of reality. Through our case study using first-person design and a field study, we offer implications for critical, reflective, more-than-human and ludic design to engage AI technologies; the conceptualisation of an RtD research space which contributes to AI literacy discourses; and outline a research trajectory concerning materiality and design affordances of AI technologies.
URL: https://doi.org/10.1145/3544548.3581175

Title: Understanding Dark Patterns in Home IoT Devices
Abstract: Internet-of-Things (IoT) devices are ubiquitous, but little attention has been paid to how they may incorporate dark patterns despite consumer protections and privacy concerns arising from their unique access to intimate spaces and always-on capabilities. This paper conducts a systematic investigation of dark patterns in 57 popular, diverse smart home devices. We update manual interaction and annotation methods for the IoT context, then analyze dark pattern frequency across device types, manufacturers, and interaction modalities. We find that dark patterns are pervasive in IoT experiences, but manifest in diverse ways across device traits. Speakers, doorbells, and camera devices contain the most dark patterns, with manufacturers of such devices (Amazon and Google) having the most dark patterns compared to other vendors. We investigate how this distribution impacts the potential for consumer exposure to dark patterns, discuss broader implications for key stakeholders like designers and regulators, and identify opportunities for future dark patterns study.
URL: https://doi.org/10.1145/3544548.3581432

Title: Vim: Customizable, Decomposable Electrical Energy Storage
Abstract: Providing electrical power is essential for nearly all interactive technologies, yet it often remains an afterthought. Some designs handwave power altogether as an “exercise for later.” Others hastily string together batteries to meet the system’s electrical requirements, enclosing them in whatever box fits. Vim is a new approach – it elevates power as a first-class design element; it frees power from being a series of discrete elements, instead catering to exact requirements; it enables power to take on new, flexible forms; it is fabricated using low-cost, accessible materials and technologies; finally, it advances sustainability by being rechargeable, non-toxic, edible, and compostable. Vims are decomposable battery alternatives that rapidly charge and can power small applications for hours. We present Vims, detail their characteristics, offer design guidelines for their fabrication, and explore their use in applications spanning prototyping, fashion, and food, including novel systems that are entirely decomposable and edible.
URL: https://doi.org/10.1145/3544548.3581110

Title: Are Two Heads Better Than One in AI-Assisted Decision Making? Comparing the Behavior and Performance of Groups and Individuals in Human-AI Collaborative Recidivism Risk Assessment
Abstract: With the prevalence of AI assistance in decision making, a more relevant question to ask than the classical question of “are two heads better than one?’’ is how groups’ behavior and performance in AI-assisted decision making compare with those of individuals’. In this paper, we conduct a case study to compare groups and individuals in human-AI collaborative recidivism risk assessment along six aspects, including decision accuracy and confidence, appropriateness of reliance on AI, understanding of AI, decision-making fairness, and willingness to take accountability. Our results highlight that compared to individuals, groups rely on AI models more regardless of their correctness, but they are more confident when they overturn incorrect AI recommendations. We also find that groups make fairer decisions than individuals according to the accuracy equality criterion, and groups are willing to give AI more credit when they make correct decisions. We conclude by discussing the implications of our work.
URL: https://doi.org/10.1145/3544548.3581015

Title: Augmenting Pathologists with NaviPath: Design and Evaluation of a Human-AI Collaborative Navigation System
Abstract: Artificial Intelligence (AI) brings advancements to support pathologists in navigating high-resolution tumor images to search for pathology patterns of interest. However, existing AI-assisted tools have not realized this promised potential due to a lack of insight into pathology and HCI considerations for pathologists’ navigation workflows in practice. We first conducted a formative study with six medical professionals in pathology to capture their navigation strategies. By incorporating our observations along with the pathologists’ domain knowledge, we designed NaviPath&nbsp;— a human-AI collaborative navigation system. An evaluation study with 15 medical professionals in pathology indicated that: (i)&nbsp;compared to the manual navigation, participants saw more than twice the number of pathological patterns in unit time with NaviPath, and (ii)&nbsp;participants achieved higher precision and recall against the AI and the manual navigation on average. Further qualitative analysis revealed that navigation was more consistent with NaviPath, which can improve the overall examination quality.
URL: https://doi.org/10.1145/3544548.3580694

Title: Comparing Zealous and Restrained AI Recommendations in a Real-World Human-AI Collaboration Task
Abstract: When designing an AI-assisted decision-making system, there is often a tradeoff between precision and recall in the AI’s recommendations. We argue that careful exploitation of this tradeoff can harness the complementary strengths in the human-AI collaboration to significantly improve team performance. We investigate a real-world video anonymization task for which recall is paramount and more costly to improve. We analyze the performance of 78 professional annotators working with a) no AI assistance, b) a high-precision "restrained" AI, and c) a high-recall "zealous" AI in over 3,466 person-hours of annotation work. In comparison, the zealous AI helps human teammates achieve significantly shorter task completion time and higher recall. In a follow-up study, we remove AI assistance for everyone and find negative training effects on annotators trained with the restrained AI. These findings and our analysis point to important implications for the design of AI assistance in recall-demanding scenarios.
URL: https://doi.org/10.1145/3544548.3581282

Title: Competent but Rigid: Identifying the Gap in Empowering AI to Participate Equally in Group Decision-Making
Abstract: Existing research on human-AI collaborative decision-making focuses mainly on the interaction between AI and individual decision-makers. There is a limited understanding of how AI may perform in group decision-making. This paper presents a wizard-of-oz study in which two participants and an AI form a committee to rank three English essays. One novelty of our study is that we adopt a speculative design by endowing AI equal power to humans in group decision-making. We enable the AI to discuss and vote equally with other human members. We find that although the voice of AI is considered valuable, AI still plays a secondary role in the group because it cannot fully follow the dynamics of the discussion and make progressive contributions. Moreover, the divergent opinions of our participants regarding an “equal AI” shed light on the possible future of human-AI relations.
URL: https://doi.org/10.1145/3544548.3581131

Title: Don’t Just Tell Me, Ask Me: AI Systems That Intelligently Frame Explanations as Questions Improve Human Logical Discernment Accuracy over Causal AI Explanations
Abstract: Critical thinking is an essential human skill. Despite the importance of critical thinking, research reveals that our reasoning ability suffers from personal biases and cognitive resource limitations, leading to potentially dangerous outcomes. This paper presents the novel idea of AI-framed Questioning that turns information relevant to the AI classification into questions to actively engage users’ thinking and scaffold their reasoning process. We conducted a study with 204 participants comparing the effects of AI-framed Questioning on a critical thinking task; discernment of logical validity of socially divisive statements. Our results show that compared to no feedback and even causal AI explanations of an always correct system, AI-framed Questioning significantly increase human discernment of logically flawed statements. Our experiment exemplifies a future style of Human-AI co-reasoning system, where the AI becomes a critical thinking stimulator rather than an information teller.
URL: https://doi.org/10.1145/3544548.3580672

Title: Interaction of Thoughts: Towards Mediating Task Assignment in Human-AI Cooperation with a Capability-Aware Shared Mental Model
Abstract: The existing work on task assignment of human-AI cooperation did not consider the differences between individual team members regarding their capabilities, leading to sub-optimal task completion results. In this work, we propose a capability-aware shared mental model (CASMM) with the components of task grouping and negotiation, which utilize tuples to break down tasks into sets of scenarios relating to difficulties and then dynamically merge the task grouping ideas raised by human and AI through negotiation. We implement a prototype system and a 3-phase user study for the proof of concept via an image labeling task. The result shows building CASMM boosts the accuracy and time efficiency significantly through forming the task assignment close to real capabilities within few iterations. It helps users better understand the capability of AI and themselves. Our method has the potential to generalize to other scenarios such as medical diagnoses and automatic driving in facilitating better human-AI cooperation.
URL: https://doi.org/10.1145/3544548.3580983

Title: AI Shall Have No Dominion: On How to Measure Technology Dominance in AI-Supported Human Decision-Making
Abstract: In this article, we propose a conceptual and methodological framework for measuring the impact of the introduction of AI systems in decision settings, based on the concept of technological dominance, i.e. the influence that an AI system can exert on human judgment and decisions. We distinguish between a negative component of dominance (automation bias) and a positive one (algorithm appreciation) by focusing on and systematizing the patterns of interaction between human judgment and AI support, or reliance patterns, and their associated cognitive effects. We then define statistical approaches for measuring these dimensions of dominance, as well as corresponding qualitative visualizations. By reporting about four medical case studies, we illustrate how the proposed methods can be used to inform assessments of dominance and of related cognitive biases in real-world settings. Our study lays the groundwork for future investigations into the effects of introducing AI support into naturalistic and collaborative decision-making.
URL: https://doi.org/10.1145/3544548.3581095

Title: Co-Writing Screenplays and Theatre Scripts with Language Models: Evaluation by Industry Professionals
Abstract: Language models are increasingly attracting interest from writers. However, such models lack long-range semantic coherence, limiting their usefulness for longform creative writing. We address this limitation by applying language models hierarchically, in a system we call Dramatron. By building structural context via prompt chaining, Dramatron can generate coherent scripts and screenplays complete with title, characters, story beats, location descriptions, and dialogue. We illustrate Dramatron’s usefulness as an interactive co-creative system with a user study of 15 theatre and film industry professionals. Participants co-wrote theatre scripts and screenplays with Dramatron and engaged in open-ended interviews. We report reflections both from our interviewees and from independent reviewers who critiqued performances of several of the scripts to illustrate how both Dramatron and hierarchical text generation could be useful for human-machine co-creativity. Finally, we discuss the suitability of Dramatron for co-creativity, ethical considerations—including plagiarism and bias—and participatory models for the design and deployment of such tools.
URL: https://doi.org/10.1145/3544548.3581225

Title: Investigating How Practitioners Use Human-AI Guidelines: A Case Study on the People + AI Guidebook
Abstract: Artificial intelligence (AI) presents new challenges for the user experience (UX) of products and services. Recently, practitioner-facing resources and design guidelines have become available to ease some of these challenges. However, little research has investigated if and how these guidelines are used, and how they impact practice. In this paper, we investigated how industry practitioners use the People + AI Guidebook. We conducted interviews with 31 practitioners (i.e., designers, product managers) to understand how they use human-AI guidelines when designing AI-enabled products. Our findings revealed that practitioners use the guidebook not only for addressing AI’s design challenges, but also for education, cross-functional communication, and for developing internal resources. We uncovered that practitioners desire more support for early phase ideation and problem formulation to avoid AI product failures. We discuss the implications for future resources aiming to help practitioners in designing AI products.
URL: https://doi.org/10.1145/3544548.3580900

Title: Modeling Touch-Based Menu Selection Performance of Blind Users via Reinforcement Learning
Abstract: Although menu selection has been extensively studied in HCI, most existing studies have focused on sighted users, leaving blind users’ menu selection under-studied. In this paper, we propose a computational model that can simulate blind users’ menu selection performance and strategies, including the way they use techniques like swiping, gliding, and direct touch. We assume that selection behavior emerges as an adaptation to the user’s memory of item positions based on experience and feedback from the screen reader. A key aspect of our model is a model of long-term memory, predicting how a user recalls and forgets item position based on previous menu selections. We compare simulation results predicted by our model against data obtained in an empirical study with ten blind users. The model correctly simulated the effect of the menu length and menu arrangement on selection time, the action composition, and the menu selection strategy of the users.
URL: https://doi.org/10.1145/3544548.3580640

Title: User Preference and Performance Using Tagging and Browsing for Image Labeling
Abstract: Visual content must be labeled to facilitate navigation and retrieval, or provide ground truth data for supervised machine learning approaches. The efficiency of labeling techniques is crucial to produce numerous qualitative labels, but existing techniques remain sparsely evaluated. We systematically evaluate the efficiency of tagging and browsing tasks in relation to the number of images displayed, interaction modes, and the image visual complexity. Tagging consists in focusing on a single image to assign multiple labels (image-oriented strategy), and browsing in focusing on a single label to assign to multiple images (label-oriented strategy). In a first experiment, we focus on the nudges inducing participants to adopt one of the strategies (n=18). In a second experiment, we evaluate the efficiency of the strategies (n=24). Results suggest an image-oriented strategy (tagging task) leads to shorter annotation times, especially for complex images, and participants tend to adopt it regardless of the conditions they face.
URL: https://doi.org/10.1145/3544548.3580926

Title: What is Human-Centered about Human-Centered AI? A Map of the Research Landscape
Abstract: The application of Artificial Intelligence (AI) across a wide range of domains comes with both high expectations of its benefits and dire predictions of misuse. While AI systems have largely been driven by a technology-centered design approach, the potential societal consequences of AI have mobilized both HCI and AI researchers towards researching human-centered artificial intelligence (HCAI). However, there remains considerable ambiguity about what it means to frame, design and evaluate HCAI. This paper presents a critical review of the large corpus of peer-reviewed literature emerging on HCAI in order to characterize what the community is defining as HCAI. Our review contributes an overview and map of HCAI research based on work that explicitly mentions the terms ‘human-centered artificial intelligence’ or ‘human-centered machine learning’ or their variations, and suggests future challenges and research directions. The map reveals the breadth of research happening in HCAI, established clusters and the emerging areas of Interaction with AI and Ethical AI. The paper contributes a new definition of HCAI, and calls for greater collaboration between AI and HCI research, and new HCAI constructs.
URL: https://doi.org/10.1145/3544548.3580959

Title: A Human-Computer Collaborative Editing Tool for Conceptual Diagrams
Abstract: Editing (e.g., editing conceptual diagrams) is a typical office task that requires numerous tedious GUI operations, resulting in poor interaction efficiency and user experience, especially on mobile devices. In this paper, we present a new type of human-computer collaborative editing tool (CET) that enables accurate and efficient editing with little interaction effort. CET divides the task into two parts, and the human and the computer focus on their respective specialties: the human describes high-level editing goals with multimodal commands, while the computer calculates, recommends, and performs detailed operations. We conducted a formative study (N = 16) to determine the concrete task division and implemented the tool on Android devices for the specific tasks of editing concept diagrams. The user study (N = 24 + 20) showed that it increased diagram editing speed by 32.75% compared with existing state-of-the-art commercial tools and led to better editing results and user experience.
URL: https://doi.org/10.1145/3544548.3580676

Title: From User Perceptions to Technical Improvement: Enabling People Who Stutter to Better Use Speech Recognition
Abstract: Consumer speech recognition systems do not work as well for many people with speech differences, such as stuttering, relative to the rest of the general population. However, what is not clear is the degree to which these systems do not work, how they can be improved, or how much people want to use them. In this paper, we first address these questions using results from a 61-person survey from people who stutter and find participants want to use speech recognition but are frequently cut off, misunderstood, or speech predictions do not represent intent. In a second study, where 91 people who stutter recorded voice assistant commands and dictation, we quantify how dysfluencies impede performance in a consumer-grade speech recognition system. Through three technical investigations, we demonstrate how many common errors can be prevented, resulting in a system that cuts utterances off 79.1% less often and improves word error rate from 25.4% to 9.9%.
URL: https://doi.org/10.1145/3544548.3581224

Title: PaTAT: Human-AI Collaborative Qualitative Coding with Explainable Interactive Rule Synthesis
Abstract: Over the years, the task of AI-assisted data annotation has seen remarkable advancements. However, a specific type of annotation task, the qualitative coding performed during thematic analysis, has characteristics that make effective human-AI collaboration difficult. Informed by a formative study, we designed PaTAT, a new AI-enabled tool that uses an interactive program synthesis approach to learn flexible and expressive patterns over user-annotated codes in real-time as users annotate data. To accommodate the ambiguous, uncertain, and iterative nature of thematic analysis, the use of user-interpretable patterns allows users to understand and validate what the system has learned, make direct fixes, and easily revise, split, or merge previously annotated codes. This new approach also helps human users to learn data characteristics and form new theories in addition to facilitating the “learning” of the AI model. PaTAT’s usefulness and effectiveness were evaluated in a lab user study.
URL: https://doi.org/10.1145/3544548.3581352

Title: ReMotion: Supporting Remote Collaboration in Open Space with Automatic Robotic Embodiment
Abstract: Design activities, such as brainstorming or critique, often take place in open spaces combining whiteboards and tables to present artefacts. In co-located settings, peripheral awareness enables participants to understand each other’s locus of attention with ease. However, these spatial cues are mostly lost while using videoconferencing tools. Telepresence robots could bring back a sense of presence, but controlling them is distracting. To address this problem, we present ReMotion, a fully automatic robotic proxy designed to explore a new way of supporting non-collocated open-space design activities. ReMotion combines a commodity body tracker (Kinect) to capture a user’s location and orientation over a wide area with a minimally invasive wearable system (NeckFace) to capture facial expressions. Due to its omnidirectional platform, ReMotion embodiment can render a wide range of body movements. A formative evaluation indicated that our system enhances the sharing of attention and the sense of co-presence enabling seamless movement-in-space during a design review task.
URL: https://doi.org/10.1145/3544548.3580699

Title: Slide4N: Creating Presentation Slides from Computational Notebooks with Human-AI Collaboration
Abstract: Data scientists often have to use other presentation tools (e.g., Microsoft PowerPoint) to create slides to communicate their analysis obtained using computational notebooks. Much tedious and repetitive work is needed to transfer the routines of notebooks (e.g., code, plots) to the presentable contents on slides (e.g., bullet points, figures). We propose a human-AI collaborative approach and operationalize it within Slide4N, an interactive AI assistant for data scientists to create slides from computational notebooks. Slide4N leverages advanced natural language processing techniques to distill key information from user-selected notebook cells and then renders them in appropriate slide layouts. The tool also provides intuitive interactions that allow further refinement and customization of the generated slides. We evaluated Slide4N with a two-part user study, where participants appreciated this human-AI collaborative approach compared to fully-manual or fully-automatic methods. The results also indicate the usefulness and effectiveness of Slide4N in slide creation tasks from notebooks.
URL: https://doi.org/10.1145/3544548.3580753

Title: ThingShare: Ad-Hoc Digital Copies of Physical Objects for Sharing Things in Video Meetings
Abstract: In video meetings, individuals may wish to share various physical objects with remote participants, such as physical documents, design prototypes, and personal belongings. However, our formative study discovered that this poses several challenges, including difficulties in referencing a remote user’s physical objects, the limited visibility of the object, and the friction of properly framing and orienting an object to the camera. To address these challenges, we propose ThingShare, a video-conferencing system designed to facilitate the sharing of physical objects during remote meetings. With ThingShare, users can quickly create digital copies of physical objects in the video feeds, which can then be magnified on a separate panel for focused viewing, overlaid on the user’s video feed for sharing in context, and stored in the object drawer for reviews. Our user study demonstrated that ThingShare made initiating object-centric conversations more efficient and provided a more stable and comprehensive view of shared objects.
URL: https://doi.org/10.1145/3544548.3581148

Title: Enabling Conversational Interaction with Mobile UI Using Large Language Models
Abstract: Conversational agents show the promise to allow users to interact with mobile devices using language. However, to perform diverse UI tasks with natural language, developers typically need to create separate datasets and models for each specific task, which is expensive and effort-consuming. Recently, pre-trained large language models (LLMs) have been shown capable of generalizing to various downstream tasks when prompted with a handful of examples from the target task. This paper investigates the feasibility of enabling versatile conversational interactions with mobile UIs using a single LLM. We designed prompting techniques to adapt an LLM to mobile UIs. We experimented with four important modeling tasks that address various scenarios in conversational interaction. Our method achieved competitive performance on these challenging tasks without requiring dedicated datasets and training, offering a lightweight and generalizable approach to enable language-based mobile interaction.
URL: https://doi.org/10.1145/3544548.3580895

Title: Evaluating Large Language Models in Generating Synthetic HCI Research Data: A Case Study
Abstract: Collecting data is one of the bottlenecks of Human-Computer Interaction (HCI) research. Motivated by this, we explore the potential of large language models (LLMs) in generating synthetic user research data. We use OpenAI’s GPT-3 model to generate open-ended questionnaire responses about experiencing video games as art, a topic not tractable with traditional computational user models. We test whether synthetic responses can be distinguished from real responses, analyze errors of synthetic data, and investigate content similarities between synthetic and real data. We conclude that GPT-3 can, in this context, yield believable accounts of HCI experiences. Given the low cost and high speed of LLM data generation, synthetic data should be useful in ideating and piloting new experiments, although any findings must obviously always be validated with real data. The results also raise concerns: if employed by malicious users of crowdsourcing services, LLMs may make crowdsourcing of self-report data fundamentally unreliable.
URL: https://doi.org/10.1145/3544548.3580688

Title: On the Design of AI-Powered Code Assistants for Notebooks
Abstract: AI-powered code assistants, such as Copilot, are quickly becoming a ubiquitous component of contemporary coding contexts. Among these environments, computational notebooks, such as Jupyter, are of particular interest as they provide rich interface affordances that interleave code and output in a manner that allows for both exploratory and presentational work. Despite their popularity, little is known about the appropriate design of code assistants in notebooks. We investigate the potential of code assistants in computational notebooks by creating a design space (reified from a survey of extant tools) and through an interview-design study (with 15 practicing data scientists). Through this work, we identify challenges and opportunities for future systems in this space, such as the value of disambiguation for tasks like data visualization, the potential of tightly scoped domain-specific tools (like linters), and the importance of polite assistants.
URL: https://doi.org/10.1145/3544548.3580940

Title: PopBlends: Strategies for Conceptual Blending with Large Language Models
Abstract: Pop culture is an important aspect of communication. On social media people often post pop culture reference images that connect an event, product or other entity to a pop culture domain. Creating these images is a creative challenge that requires finding a conceptual connection between the users’ topic and a pop culture domain. In cognitive theory, this task is called conceptual blending. We present a system called PopBlends that automatically suggests conceptual blends. The system explores three approaches that involve both traditional knowledge extraction methods and large language models. Our annotation study shows that all three methods provide connections with similar accuracy, but with very different characteristics. Our user study shows that people found twice as many blend suggestions as they did without the system, and with half the mental demand. We discuss the advantages of combining large language models with knowledge bases for supporting divergent and convergent thinking.
URL: https://doi.org/10.1145/3544548.3580948

Title: Synthetic Lies: Understanding AI-Generated Misinformation and Evaluating Algorithmic and Human Solutions
Abstract: Large language models have abilities in creating high-volume human-like texts and can be used to generate persuasive misinformation. However, the risks remain under-explored. To address the gap, this work first examined characteristics of AI-generated misinformation (AI-misinfo) compared with human creations, and then evaluated the applicability of existing solutions. We compiled human-created COVID-19 misinformation and abstracted it into narrative prompts for a language model to output AI-misinfo. We found significant linguistic differences within human-AI pairs, and patterns of AI-misinfo in enhancing details, communicating uncertainties, drawing conclusions, and simulating personal tones. While existing models remained capable of classifying AI-misinfo, a significant performance drop compared to human-misinfo was observed. Results suggested that existing information assessment guidelines had questionable applicability, as AI-misinfo tended to meet criteria in evidence credibility, source transparency, and limitation acknowledgment. We discuss implications for practitioners, researchers, and journalists, as AI can create new challenges to the societal problem of misinformation.
URL: https://doi.org/10.1145/3544548.3581318

Title: Why Johnny Can’t Prompt: How Non-AI Experts Try (and Fail) to Design LLM Prompts
Abstract: Pre-trained large language models (“LLMs”) like GPT-3 can engage in fluent, multi-turn instruction-taking out-of-the-box, making them attractive materials for designing natural language interactions. Using natural language to steer LLM outputs (“prompting”) has emerged as an important design technique potentially accessible to non-AI-experts. Crafting effective prompts can be challenging, however, and prompt-based interactions are brittle. Here, we explore whether non-AI-experts can successfully engage in “end-user prompt engineering” using a design probe—a prototype LLM-based chatbot design tool supporting development and systematic evaluation of prompting strategies. Ultimately, our probe participants explored prompt designs opportunistically, not systematically, and struggled in ways echoing end-user programming systems and interactive machine learning systems. Expectations stemming from human-to-human instructional experiences, and a tendency to overgeneralize, were barriers to effective prompt design. These findings have implications for non-AI-expert-facing LLM-based tool design and for improving LLM-and-prompt literacy among programmers and the public, and present opportunities for further research.
URL: https://doi.org/10.1145/3544548.3581388

Title: Causalvis: Visualizations for Causal Inference
Abstract: Causal inference is a statistical paradigm for quantifying causal effects using observational data. It is a complex process, requiring multiple steps, iterations, and collaborations with domain experts. Analysts often rely on visualizations to evaluate the accuracy of each step. However, existing visualization toolkits are not designed to support the entire causal inference process within computational environments familiar to analysts. In this paper, we address this gap with Causalvis, a Python visualization package for causal inference. Working closely with causal inference experts, we adopted an iterative design process to develop four interactive visualization modules to support causal inference analysis tasks. The modules are then presented back to the experts for feedback and evaluation. We found that Causalvis effectively supported the iterative causal inference process. We discuss the implications of our findings for designing visualizations for causal inference, particularly for tasks of communication and collaboration.
URL: https://doi.org/10.1145/3544548.3581236

Title: CrowdIDEA: Blending Crowd Intelligence and Data Analytics to Empower Causal Reasoning
Abstract: Causal reasoning is crucial for people to understand data, make decisions, or take action. However, individuals often have blind spots and overlook alternative hypotheses, and using only data is insufficient for causal reasoning. We designed and implemented CrowdIDEA, a novel tool consisting of a three-panel integration incorporating the crowd’s beliefs (Crowd Panel with two designs), data analytics (Data Panel), and user’s causal diagram (Diagram Panel) to stimulate causal reasoning. Through an experiment with 54 participants, we showed the significant effects of the Crowd Panel designs on the outcomes of causal reasoning, such as an increased number of causal beliefs generated. Participants also devised new strategies for bootstrapping, strengthening, deepening, and explaining their causal beliefs, as well as taking advantage of the unique characteristics of both qualitative and quantitative data sources to reduce potential biases in reasoning. Our work makes theoretical and design implications for exploratory causal reasoning.
URL: https://doi.org/10.1145/3544548.3581021

Title: GVQA: Learning to Answer Questions about Graphs with Visualizations via Knowledge Base
Abstract: Graphs are common charts used to represent the topological relationship between nodes. It is a powerful tool for data analysis and information retrieval tasks involve asking questions about graphs. In formative study, we found that questions for graphs are not only about the relationship of nodes but also about the properties of graph elements. We propose a pipeline to answer natural language questions about graph visualizations and generate visual answers. We first extract the data from graphs and convert them into GML format. We design data structures to encode graph information and convert them into an knowledge base. We then extract topic entities from questions. We feed questions, entities and knowledge bases into our question-answer model to obtain the SPARQL queries for textual answers. Finally, we design a module to present the answers visually. A user study demonstrates that these visual and textual answers are useful, credible and and transparent.
URL: https://doi.org/10.1145/3544548.3581067

Title: MetaExplorer : Facilitating Reasoning with Epistemic Uncertainty in Meta-Analysis
Abstract: Scientists often use meta-analysis to characterize the impact of an intervention on some outcome of interest across a body of literature. However, threats to the utility and validity of meta-analytic estimates arise when scientists average over potentially important variations in context like different research designs. Uncertainty about quality and commensurability of evidence casts doubt on results from meta-analysis, yet existing software tools for meta-analysis do not provide an explicit software representation of these concerns. We present MetaExplorer, a prototype system for meta-analysis that we developed using iterative design with meta-analysis experts to provide a guided process for eliciting assessments of uncertainty and reasoning about how to incorporate them during statistical inference. Our qualitative evaluation of MetaExplorer with experienced meta-analysts shows that imposing a structured workflow both elevates the perceived importance of epistemic concerns and presents opportunities for tools to engage users in dialogue around goals and standards for evidence aggregation.
URL: https://doi.org/10.1145/3544548.3580869

Title: Visual Belief Elicitation Reduces the Incidence of False Discovery
Abstract: Visualization supports exploratory data analysis (EDA), but EDA frequently presents spurious charts, which can mislead people into drawing unwarranted conclusions. We investigate interventions to prevent false discovery from visualized data. We evaluate whether eliciting analyst beliefs helps guard against the over-interpretation of noisy visualizations. In two experiments, we exposed participants to both spurious and ‘true’ scatterplots, and assessed their ability to infer data-generating models that underlie those samples. Participants who underwent prior belief elicitation made 21% more correct inferences along with 12% fewer false discoveries. This benefit was observed across a variety of sample characteristics, suggesting broad utility to the intervention. However, additional interventions to highlight counterevidence and sample uncertainty did not provide significant advantage. Our findings suggest that lightweight, belief-driven interactions can yield a reliable, if moderate, reduction in false discovery. This work also suggests future directions to improve visual inference and reduce bias.
URL: https://doi.org/10.1145/3544548.3580808

Title: Why Combining Text and Visualization Could Improve Bayesian Reasoning: A Cognitive Load Perspective
Abstract: Investigations into using visualization to improve Bayesian reasoning and advance risk communication have produced mixed results, suggesting that cognitive ability might affect how users perform with different presentation formats. Our work examines the cognitive load elicited when solving Bayesian problems using icon arrays, text, and a juxtaposition of text and icon arrays. We used a three-pronged approach to capture a nuanced picture of cognitive demand and measure differences in working memory capacity, performance under divided attention using a dual-task paradigm, and subjective ratings of self-reported effort. We found that individuals with low working memory capacity made fewer errors and experienced less subjective workload when the problem contained an icon array compared to text alone, showing that visualization improves accuracy while exerting less cognitive demand. We believe these findings can considerably impact accessible risk communication, especially for individuals with low working memory capacity.
URL: https://doi.org/10.1145/3544548.3581218

Title: CrossCode: Multi-Level Visualization of Program Execution
Abstract: Program visualizations help to form useful mental models of how programs work, and to reason and debug code. But these visualizations exist at a fixed level of abstraction, e.g., line-by-line. In contrast, programmers switch between many levels of abstraction when inspecting program behavior. Based on results from a formative study of hand-designed program visualizations, we designed CrossCode, a web-based program visualization system for JavaScript that leverages structural cues in syntax, control flow, and data flow to aggregate and navigate program execution across multiple levels of abstraction. In an exploratory qualitative study with experts, we found that CrossCode enabled participants to maintain a strong sense of place in program execution, was conducive to explaining program behavior, and helped track changes and updates to the program state.
URL: https://doi.org/10.1145/3544548.3581390

Title: Log-It: Supporting Programming with Interactive, Contextual, Structured, and Visual Logs
Abstract: Logging is a widely used technique for inspecting and understanding programs. However, the presentation of logs still often takes its ancient form of a linear stream of text that resides in a terminal, console, or log file. Despite its simplicity, interpreting log output is often challenging due to the large number of textual logs that lack structure and context. We conducted content analysis and expert interviews to understand the practices and challenges inherent in logging. These activities demonstrated that the current representation of logs does not provide the rich structures programmers need to interpret them or the program’s behavior. We present Log-it, a logging interface that enables programmers to interactively structure and visualize logs in situ. A user study with novices and experts showed that Log-it’s syntax and interface have a minimal learning curve, and the interactive representations and organizations of logs help programmers easily locate, synthesize, and understand logs.
URL: https://doi.org/10.1145/3544548.3581403

Title: Structured Editing for All: Deriving Usable Structured Editors from Grammars
Abstract: Structured editing can show benefits in learnability, tool building, and editing efficiency in programming. However, creating a usable structured editor is laborious and demanding, typically requiring tool builders to manually create or adjust editing interactions. We present Sandblocks, a system that allows users to automatically generate structured editors for every language with a formal grammar available. Our system’s input reconciliation process acts on arbitrary syntax trees to provides consistent interactions across our generated editors. Our editors’ editing experience is designed to be familiar to users from textual editing but, compared to previous work, requires no manual annotation in the grammars. We demonstrate our editors’ usability across languages through a user study (N=18). Compared to conventional text editors, even with minimal training, participants only took on average 21% (JS), 34% (Clojure), and 95% (RegExp) longer and reported that editing felt natural with a score of 6/7.
URL: https://doi.org/10.1145/3544548.3580785

Title: VizProg: Identifying Misunderstandings By Visualizing Students’ Coding Progress
Abstract: Programming instructors often conduct in-class exercises to help them identify students that are falling behind and surface students’ misconceptions. However, as we found in interviews with programming instructors, monitoring students’ progress during exercises is difficult, particularly for large classes. We present VizProg, a system that allows instructors to monitor and inspect students’ coding progress in real-time during in-class exercises. VizProg represents students’ statuses as a 2D Euclidean spatial map that encodes the students’ problem-solving approaches and progress in real-time. VizProg allows instructors to navigate the temporal and structural evolution of students’ code, understand relationships between code, and determine when to provide feedback. A comparison experiment showed that VizProg helped to identify more students’ problems than a baseline system. VizProg also provides richer and more comprehensive information for identifying important student behavior. By managing students’ activities at scale, this work presents a new paradigm for improving the quality of live learning.
URL: https://doi.org/10.1145/3544548.3581516

Title: “What If Everyone is Able to Program?” – Exploring the Role of Software Development in Science Fiction
Abstract: For decades, research around emerging technologies has been inspired by science fiction and vice versa. While so far almost only the technologies themselves have been considered, we explore the underlying software development and programming approaches. We therefore conduct a detailed media content analysis of twenty-seven movies that examines the role of software development in science fiction by identifying and investigating new approaches to programming and how software development is conceptualized portrayed within science fiction scenes. With the additional analysis of eighteen design fiction stories exploring the scenario “What if everyone is able to program?”, we envision potential impacts of the democratization of software development on business and society. Our study opens new discussions and perspectives, by investigating the current vision of the future of programming and uncovers new approaches to software development which can serve as a starting point for further research in the HCI community.
URL: https://doi.org/10.1145/3544548.3581436

Title: “What It Wants Me To Say”: Bridging the Abstraction Gap Between End-User Programmers and Code-Generating Large Language Models
Abstract: Code-generating large language models map natural language to code. However, only a small portion of the infinite space of naturalistic utterances is effective at guiding code generation. For non-expert end-user programmers, learning this is the challenge of abstraction matching. We examine this challenge in the specific context of data analysis in spreadsheets, in a system that maps the user’s natural language query to Python code using the Codex generator, executes the code, and shows the result. We propose grounded abstraction matching, which bridges the abstraction gap by translating the code back into a systematic and predictable naturalistic utterance. In a between-subjects, think-aloud study (n=24), we compare grounded abstraction matching to an ungrounded alternative based on previously established query framing principles. We find that the grounded approach improves end-users’ understanding of the scope and capabilities of the code-generating model, and the kind of language needed to use it effectively.
URL: https://doi.org/10.1145/3544548.3580817

Title: Collaborative Online Learning with VR Video: Roles of Collaborative Tools and Shared Video Control
Abstract: Virtual Reality (VR) has a noteworthy educational potential by providing immersive and collaborative environments. As an alternative but cost-effective way of delivering realistic environments in VR, using 360-degree videos in immersive VR (VR videos) received more attention. Although many studies reported positive learning experiences with VR videos, little is known about how collaborative learning performs on VR video viewing systems. In this study, we implemented two collaborative VR video viewing modes based on the way of group video control, synchronized or shared (Sync mode) and non-synchronized or individual (Non-sync mode) video control, against a conventional VR video viewing setting (Basic mode). We conducted a within-subject study (N = 54) in a lab-simulated remote learning environment. Our results show that collaborative VR video modes (Sync and Non-sync mode) improve users’ learning experiences and collaboration quality, especially with shared video control. Our findings provide directions for designing and employing collaborative VR video tools in online learning environments.
URL: https://doi.org/10.1145/3544548.3581395

Title: Dancing with the Avatars: Minimal Avatar Customisation Enhances Learning in a Psychomotor Task
Abstract: Virtual environments can support psychomotor learning by allowing learners to observe instructor avatars. Instructor avatars that look like the learner hold promise in enhancing learning; however, it is unclear whether this works for psychomotor tasks and how similar avatars need to be. We investigated ‘minimal’ customisation of instructor avatars, approximating a learner’s appearance by matching only key visual features: gender, skin-tone, and hair colour. These avatars can be created easily and avoid problems of highly similar avatars. Using modern dancing as a skill to learn, we compared the effects of visually similar and dissimilar avatars, considering both learning on a screen (n=59) and in VR (n=38). Our results indicate that minimal avatar customisation leads to significantly more vivid visual imagery of the dance moves than dissimilar avatars. We analyse variables affecting interindividual differences, discuss the results in relation to theory, and derive design implications for psychomotor training in virtual environments.
URL: https://doi.org/10.1145/3544548.3580944

Title: FakeForward: Using Deepfake Technology for Feedforward Learning
Abstract: Videos are commonly used to support learning of new skills, to improve existing skills, and as a source of motivation for training. Video self-modelling (VSM) is a learning technique that improves performance and motivation by showing a user a video of themselves performing a skill at a level they have not yet achieved. Traditional VSM is very data and labour intensive: a lot of video footage needs to be collected and manually edited in order to create an effective self-modelling video. We address this by presenting FakeForward – a method which uses deepfakes to create self-modelling videos from videos of other people. FakeForward turns videos of better-performing people into effective, personalised training tools by replacing their face with the user’s. We investigate how FakeForward can be effectively applied and demonstrate its efficacy in rapidly improving performance in physical exercises, as well as confidence and perceived competence in public speaking.
URL: https://doi.org/10.1145/3544548.3581100

Title: “Moment to Moment”: A Situated View of Teaching Ethics from the Perspective of Computing Ethics Teaching Assistants
Abstract: The HCI research community has long centered ethics in HCI research and practice. This interest has persisted as scholars highlight the need for more situated understandings and deeper integration of ethics into HCI. In parallel, HCI scholars and students have become increasingly involved in teaching computing ethics across many different university contexts, bringing in valuable perspectives informed by the connections between HCI and the socio-technical subject matter of computing ethics. Yet explicitly bringing these two threads together – examining the teaching of ethics through an HCI research lens – remains nascent. This paper integrates work in HCI and computing education to focus on the role and experience of computing ethics teaching assistants (CETAs), who are increasingly involved in ethics instruction and whose perspectives are predominantly missing in existing literature spanning HCI and computing education. Drawing on HCI theories and methods, our qualitative study of eleven CETAs at two American universities makes three contributions to the HCI literature. First, we build an understanding of who these TAs are with respect to the unique position of teaching computing ethics. Second, we characterize how CETAs’ teaching and learning is situated and shaped within different communities and institutional contexts. Finally, we suggest several implications for the design of ethics instruction within undergraduate computing programs. More broadly, our work can be viewed as a call to action, encouraging HCI scholars to play a more significant role in studying and designing the teaching and learning of computing ethics.
URL: https://doi.org/10.1145/3544548.3581572

Title: Olfactory Wearables for Mobile Targeted Memory Reactivation
Abstract: This paper investigates how a smartphone-controlled olfactory wearable might improve memory recall. We conducted a within-subjects experiment with 32 participants using the device and without (control). In the experimental condition, bursts of odor were released during visuo-spatial memory navigation tasks, and replayed during sleep the following night in the subjects’ home. We found that compared to control, there was an improvement in memory performance when using the scent wearable in memory tasks that involved walking in a physical space. Furthermore, participants recalled more objects and translations when re-exposed to the same scent during the recall test, in addition to during sleep. These effects were statistically significant, and, in the object recall task, they also persisted for more than one week. This experiment demonstrates a potential practical application of olfactory interfaces that can interact with a user during wake as well as sleep to support memory.
URL: https://doi.org/10.1145/3544548.3580892

Title: Understanding Personal Data Tracking and Sensemaking Practices for Self-Directed Learning in Non-Classroom and Non-Computer-Based Contexts
Abstract: Self-directed learning is becoming a significant skill for learners. However, learners may suffer from difficulties such as distractions, a lack of motivation, and so on. While self-tracking technologies have the potential to address these challenges, existing tools and systems mainly focused on tracking computer-based learning data in classroom contexts. Little is known about how students track and make sense of their learning data from non-classroom learning activities and which types of learning data are personally meaningful for learners. In this paper, we conducted a qualitative study with 24 users of Timing, a mobile learning tracking application in China. Our findings indicated that users tracked a variety of qualitative learning data (e.g., videos, photos of learning materials, and emotions) and made sense of this data using different strategies such as observing behavioral and contextual details in videos. We then provided implications for designing non-classroom and non-computer-based personal learning tracking tools.
URL: https://doi.org/10.1145/3544548.3581364

Title: GlanceWriter: Writing Text by Glancing Over Letters with Gaze
Abstract: Writing text with eye gaze only is an appealing hands-free text entry method. However, existing gaze-based text entry methods introduce eye fatigue and are slow in typing speed because they often require users to dwell on letters of a word, or mark the starting and ending positions of a gaze path with extra operations for entering a word. In this paper, we propose GlanceWriter, a text entry method that allows users to enter text by glancing over keys one by one without any need to dwell on any keys or specify the starting and ending positions of a gaze path when typing a word. To achieve so, GlanceWriter probabilistically determines the letters to be typed based on the dynamics of gaze movements and gaze locations. Our user studies demonstrate that GlanceWriter significantly improves the text entry performance over EyeSwipe, a dwell-free input method using “reverse crossing” to identify the starting and ending keys. GlanceWriter also outperforms the dwell-free gaze input method of Tobii’s Communicator 5, a commercial eye gaze-based communication system. Overall, GlanceWriter achieves dwell-free and crossing-free text entry by probabilistically decoding gaze paths, offering a promising gaze-based text entry method.
URL: https://doi.org/10.1145/3544548.3581269

Title: Not All Spacings Are Created Equal: The Effect of Text Spacings in On-the-Go Reading Using Optical See-Through Head-Mounted Displays
Abstract: The emergent Optical Head-Mounted Display (OHMD) platform has made mobile reading possible by superimposing digital text onto users’ view of the environment. However, mobile reading through OHMD needs to be effectively balanced with the user’s environmental awareness. Hence, a series of studies were conducted to explore how text spacing strategies facilitate such balance. Through these studies, it was found that increasing spacing within the text can significantly enhance mobile reading on OHMDs in both simple and complex navigation scenarios and that such benefits mainly come from increasing the inter-line spacing, but not inter-word spacing. Compared with existing positioning strategies, increasing inter-line spacing improves mobile OHMD information reading in terms of reading speed (11.9% faster), walking speed (3.7% faster), and switching between reading and navigation (106.8% more accurate and 33% faster).
URL: https://doi.org/10.1145/3544548.3581430

Title: ParaGlassMenu: Towards Social-Friendly Subtle Interactions in Conversations
Abstract: Interactions with digital devices during social settings can reduce social engagement and interrupt conversations. To overcome these drawbacks, we designed ParaGlassMenu, a semi-transparent circular menu that can be displayed around a conversation partner’s face on Optical See-Through Head-Mounted Display (OHMD) and interacted subtly using a ring mouse. We evaluated ParaGlassMenu with several alternative approaches (Smartphone, Voice assistant, and Linear OHMD menus) by manipulating Internet-of-Things (IoT) devices in a simulated conversation setting with a digital partner. Results indicated that the ParaGlassMenu offered the best overall performance in balancing social engagement and digital interaction needs in conversations. To validate these findings, we conducted a second study in a realistic conversation scenario involving commodity IoT devices. Results confirmed the utility and social acceptance of the ParaGlassMenu. Based on the results, we discuss implications for designing attention-maintaining subtle interaction techniques on OHMDs.
URL: https://doi.org/10.1145/3544548.3581065

Title: ResType: Invisible and Adaptive Tablet Keyboard Leveraging Resting Fingers
Abstract: Text entry on tablet touchscreens is a basic need nowadays. Tablet keyboards require visual attention for users to locate keys, thus not supporting efficient touch typing. They also take up a large proportion of screen space, which affects the access to information. To solve these problems, we propose ResType, an adaptive and invisible keyboard on three-state touch surfaces (e.g. tablets with unintentional touch prevention). ResType allows users to rest their hands on it and automatically adapts the keyboard to the resting fingers. Thus, users do not need visual attention to locate keys, which supports touch typing. We quantitatively explored users’ resting finger patterns on ResType, based on which we proposed an augmented Bayesian decoding algorithm for ResType, with 96.3% top-1 and 99.0% top-3 accuracies. After a 5-day evaluation, ResType achieved 41.26 WPM, outperforming normal tablet keyboards by 13.5% and reaching 86.7% of physical keyboards. It solves the occlusion problem while maintaining comparable typing speed with current methods on visible tablet keyboards.
URL: https://doi.org/10.1145/3544548.3581055

Title: T-Force: Exploring the Use of Typing Force for Three State Virtual Keyboards
Abstract: Three state virtual keyboards which differentiate contact events between released, touched, and pressed states have the potential to improve overall typing experience and reduce the gap between virtual keyboards and physical keyboards. Incorporating force sensitivity, three-state virtual keyboards can utilize a force threshold to better classify a contact event. However, our limited knowledge of how force plays a role during typing on virtual keyboards limits further progress. Through a series of studies we observe that using a uniform threshold is not an optimal approach. Furthermore, the force being applied while typing varies significantly across the keys and among participants. As such, we propose three different approaches to further improve the uniform threshold. We show that a carefully selected non-uniform threshold function could be sufficient in delineating typing events on a three-state keyboard. Finally, we conclude our work with lessons learned, suggestion for future improvements, and comparisons with current methods available.
URL: https://doi.org/10.1145/3544548.3580915

Title: “Together but Not Together”: Evaluating Typing Indicators for Interaction-Rich Communication
Abstract: Messaging is a ubiquitous digital communication medium. It is also a minimal medium of communication because of its inability to convey immediate feedback, tone, facial expressions, hesitations, and pauses, or follow the train of the other person’s thoughts. This paper combines quantitative and qualitative approaches for analyzing richer forms of typing indicators in messaging interfaces, such as showing text as it is typed. By assessing users’ subjective workload and interpreting these findings in the context of users’ experiences, we found that more expressive typing indicators were perceived as “rich in communication”, as they helped people communicate more allowing for closer connections. These indicators also increased users’ perceived co-presence. In addition, our research suggests there may be benefits of designing customized typing indicators for relationship maintenance and task-based communication.
URL: https://doi.org/10.1145/3544548.3581248

Title: 4Doodle: 4D Printing Artifacts Without 3D Printers
Abstract: 4D printing encodes transformability over time, which empowers users to create artifacts by on-demand deformation. The creative process of 4D printing shape-changing artifacts can be challenging because of its discontinuous fabrication steps, such as digital designing, specific path planning, automatic printing and manual triggering. We hypothesize that switching from typical 4D printing reliant on 3D printers to a more “handcrafted” method can allow users to understand and continuously reflect upon the artifact and its transformability. Towards this vision, we introduce 4Doodle, a hybrid craft approach that integrates unique deformation controllability and five techniques for freehand 4D printing, using a 3D pen. To tackle the shape-changing challenges of uncertain hands-on fabrication, we develop a mixed reality system to help novices master the manual skills of 4D printing. We also demonstrate a series of 4D printed artifacts with fully human intervention. Finally, our user study shows that 4Doodle lowers the skill-acquisition barrier associated with handcrafting 4D printed artifacts, and it has great potential for creative production and spatial ability.
URL: https://doi.org/10.1145/3544548.3581321

Title: AutomataStage: An AR-Mediated Creativity Support Tool for Hands-on Multidisciplinary Learning
Abstract: The creativity support tools can enhance the hands-on multidisciplinary learning experience by drawing interest in the process of creating the outcome. We present AutomataStage, an AR-mediated creativity support tool for hands-on multidisciplinary learning. AutomataStage utilizes a video see-through interface to support the creation of Interactive Automata. The combination of building blocks and low-cost materials increases the expressiveness. The generative design method and one-to-one guide support the idea development process. It also provides a hardware see-through feature with which inside parts and circuits can be seen and an operational see-through feature that shows the operation in real-time. The visual programming method with a state transition diagram supports the iterative process during the creation process. A user study shows that AutomataStage enabled the students to create diverse Interactive Automata within 40-minute sessions. By creating Interactive Automata, the participants could learn the basic concepts of components. See-through features allowed active exploration with interest while integrating the components. We discuss the implications of hands-on tools with interactive and kinetic content beyond multidisciplinary learning.
URL: https://doi.org/10.1145/3544548.3581408

Title: FlexBoard: A Flexible Breadboard for Interaction Prototyping on Curved and Deformable Surfaces
Abstract: We present FlexBoard, an interaction prototyping platform that enables rapid prototyping with interactive components such as sensors, actuators and displays on curved and deformable objects. FlexBoard offers the rapid prototyping capabilities of traditional breadboards but is also flexible to conform to different shapes and materials. FlexBoard’s bendability is enabled by replacing the rigid body of a breadboard with a flexible living hinge that holds the metal strips from a traditional breadboard while maintaining the standard pin spacing. In addition, FlexBoards are also shape-customizable as they can be cut to a specific length and joined together to form larger prototyping areas. We discuss FlexBoard’s mechanical design and present a technical evaluation of its bendability, adhesion to curved and deformable surfaces, and holding force of electronic components. Finally, we show the usefulness of FlexBoard through 3 application scenarios with interactive textiles, curved tangible user interfaces, and VR.
URL: https://doi.org/10.1145/3544548.3580748

Title: Handheld Tools Unleashed: Mixed-Initiative Physical Sketching with a Robotic Printer
Abstract: Personal fabrication has mostly focused on handheld tools as embodied extensions of the user, and machines like laser cutters and 3D printers automating parts of the process without intervention. Although interactive digital fabrication has been explored as a middle ground, existing systems have a fixed allocation of user intervention vs. machine autonomy, limiting flexibility, creativity, and improvisation. We explore a new class of devices that combine the desirable properties of a handheld tool and an autonomous fabrication robot, offering a continuum from manual and assisted to autonomous fabrication, with seamless mode transitions. We exemplify the concept of mixed-initiative physical sketching with a working robotic printer that can be handheld for free-hand sketching, can provide interactive assistance during sketching, or move about for computer-generated sketches. We present interaction techniques to seamlessly transition between modes, and sketching techniques benefitting from these transitions to, e.g., extend (upscale, repeat) or revisit (refine, color) sketches. Our evaluation with seven sketchers illustrates that RoboSketch successfully leverages each mode’s strengths, and that mixed-initiative physical sketching makes computer-supported sketching more flexible.
URL: https://doi.org/10.1145/3544548.3580691

Title: MechCircuit: Augmenting Laser-Cut Objects with Integrated Electronics, Mechanical Structures and Magnets
Abstract: Laser cutting revolutionizes the creation of personal-fabricated prototypes. These objects can have transformable properties by adopting different materials and be interactive by integrating electronic circuits. However, circuits in laser-cut objects always have limited movements, which refrains laser cutting from achieving interactive prototypes with more complex movable functions like mechanisms. We propose MechCircuit, a design and fabrication pipeline for making mechanical-electronical objects with laser cutting. We leverage the neodymium magnet’s natures of magnetism and conductivity to integrate electronics and mechanical structure joints into prototypes. We conduct the evaluation to explore technological parameters and assess the practical feasibility of the fabrication pipeline. And we organized a user-observing workshop for non-expert users. Through the outcoming prototypes, the result demonstrates the feasibility of MechCircuit as a useful and inspiring prototyping method.
URL: https://doi.org/10.1145/3544548.3581002

Title: Physically Situated Tools for Exploring a Grain Space in Computational Machine Knitting
Abstract: We propose an approach to enabling exploratory creativity in digital fabrication through the use of grain spaces. In material processes, “grain” describes underlying physical properties like the orientation of cellulose fibers in wood that, in aggregate, affect fabrication concerns (such as directional cutting) and outcomes (such as axes of strength and visual effects). Extending this into the realm of computational fabrication, grain spaces define a curated set of mid-level material properties as well as the underlying low-level fabrication processes needed to produce them. We specify a grain space for computational brioche knitting, use it to guide our production of a set of hybrid digital/physical tools to support quick and playful exploration of this space’s unique design affordances, and reflect on the role of such tools in creative practice.
URL: https://doi.org/10.1145/3544548.3581434

Title: CiteSee: Augmenting Citations in Scientific Papers with Persistent and Personalized Historical Context
Abstract: When reading a scholarly article, inline citations help researchers contextualize the current article and discover relevant prior work. However, it can be challenging to prioritize and make sense of the hundreds of citations encountered during literature reviews. This paper introduces CiteSee, a paper reading tool that leverages a user’s publishing, reading, and saving activities to provide personalized visual augmentations and context around citations. First, CiteSee connects the current paper to familiar contexts by surfacing known citations a user had cited or opened. Second, CiteSee helps users prioritize their exploration by highlighting relevant but unknown citations based on saving and reading history. We conducted a lab study that suggests CiteSee is significantly more effective for paper discovery than three baselines. A field deployment study shows CiteSee helps participants keep track of their explorations and leads to better situational awareness and increased paper discovery via inline citation when conducting real-world literature reviews.
URL: https://doi.org/10.1145/3544548.3580847

Title: ComLittee: Literature Discovery with Personal Elected Author Committees
Abstract: In order to help scholars understand and follow a research topic, significant research has been devoted to creating systems that help scholars discover relevant papers and authors. Recent approaches have shown the usefulness of highlighting relevant authors while scholars engage in paper discovery. However, these systems do not capture and utilize users’ evolving knowledge of authors. We reflect on the design space and introduce ComLittee, a literature discovery system that supports author-centric exploration. In contrast to paper-centric interaction in prior systems, ComLittee’s author-centric interaction supports curating research threads from individual authors, finding new authors and papers using combined signals from a paper recommender and the curated authors’ authorship graphs, and understanding them in the context of those signals. In a within-subjects experiment that compares to a paper-centric discovery system with author-highlighting, we demonstrate how ComLittee improves author and paper discovery.
URL: https://doi.org/10.1145/3544548.3581371

Title: DeepLens: Interactive Out-of-Distribution Data Detection in NLP Models
Abstract: Machine Learning (ML) has been widely used in Natural Language Processing (NLP) applications. A fundamental assumption in ML is that training data and real-world data should follow a similar distribution. However, a deployed ML model may suffer from out-of-distribution (OOD) issues due to distribution shifts in the real-world data. Though many algorithms have been proposed to detect OOD data from text corpora, there is still a lack of interactive tool support for ML developers. In this work, we propose DeepLens, an interactive system that helps users detect and explore OOD issues in massive text corpora. Users can efficiently explore different OOD types in DeepLens with the help of a text clustering method. Users can also dig into a specific text by inspecting salient words highlighted through neuron activation analysis. In a within-subjects user study with 24 participants, participants using DeepLens were able to find nearly twice more types of OOD issues accurately with 22% more confidence compared with a variant of DeepLens that has no interaction or visualization support.
URL: https://doi.org/10.1145/3544548.3580741

Title: DeepSeer: Interactive RNN Explanation and Debugging via State Abstraction
Abstract: Recurrent Neural Networks (RNNs) have been widely used in Natural Language Processing (NLP) tasks given its superior performance on processing sequential data. However, it is challenging to interpret and debug RNNs due to the inherent complexity and the lack of transparency of RNNs. While many explainable AI (XAI) techniques have been proposed for RNNs, most of them only support local explanations rather than global explanations. In this paper, we present DeepSeer, an interactive system that provides both global and local explanations of RNN behavior in multiple tightly-coordinated views for model understanding and debugging. The core of DeepSeer is a state abstraction method that bundles semantically similar hidden states in an RNN model and abstracts the model as a finite state machine. Users can explore the global model behavior by inspecting text patterns associated with each state and the transitions between states. Users can also dive into individual predictions by inspecting the state trace and intermediate prediction results of a given input. A between-subjects user study with 28 participants shows that, compared with a popular XAI technique, LIME, participants using DeepSeer made a deeper and more comprehensive assessment of RNN model behavior, identified the root causes of incorrect predictions more accurately, and came up with more actionable plans to improve the model performance.
URL: https://doi.org/10.1145/3544548.3580852

Title: Model Sketching: Centering Concepts in Early-Stage Machine Learning Model Design
Abstract: Machine learning practitioners often end up tunneling on low-level technical details like model architectures and performance metrics. Could early model development instead focus on high-level questions of which factors a model ought to pay attention to? Inspired by the practice of sketching in design, which distills ideas to their minimal representation, we introduce model sketching: a technical framework for iteratively and rapidly authoring functional approximations of a machine learning model’s decision-making logic. Model sketching refocuses practitioner attention on composing high-level, human-understandable concepts that the model is expected to reason over (e.g., profanity, racism, or sarcasm in a content moderation task) using zero-shot concept instantiation. In an evaluation with 17 ML practitioners, model sketching reframed thinking from implementation to higher-level exploration, prompted iteration on a broader range of model designs, and helped identify gaps in the problem formulation—all in a fraction of the time ordinarily required to build a model.
URL: https://doi.org/10.1145/3544548.3581290

Title: Relatedly: Scaffolding Literature Reviews with Existing Related Work Sections
Abstract: Scholars who want to research a scientific topic must take time to read, extract meaning, and identify connections across many papers. As scientific literature grows, this becomes increasingly challenging. Meanwhile, authors summarize prior research in papers’ related work sections, though this is scoped to support a single paper. A formative study found that while reading multiple related work paragraphs helps overview a topic, it is hard to navigate overlapping and diverging references and research foci. In this work, we design a system, Relatedly, that scaffolds exploring and reading multiple related work paragraphs on a topic, with features including dynamic re-ranking and highlighting to spotlight unexplored dissimilar information, auto-generated descriptive paragraph headings, and low-lighting of redundant information. From a within-subjects user study (n=15), we found that scholars generate more coherent, insightful, and comprehensive topic outlines using Relatedly compared to a baseline paper list.
URL: https://doi.org/10.1145/3544548.3580841

Title: Amortised Experimental Design and Parameter Estimation for User Models of Pointing
Abstract: User models play an important role in interaction design, supporting automation of interaction design choices. In order to do so, model parameters must be estimated from user data. While very large amounts of user data are sometimes required, recent research has shown how experiments can be designed so as to gather data and infer parameters as efficiently as possible, thereby minimising the data requirement. In the current article, we investigate a variant of these methods that amortises the computational cost of designing experiments by training a policy for choosing experimental designs with simulated participants. Our solution learns which experiments provide the most useful data for parameter estimation by interacting with in-silico agents sampled from the model space thereby using synthetic data rather than vast amounts of human data. The approach is demonstrated for three progressively complex models of pointing.
URL: https://doi.org/10.1145/3544548.3581483

Title: Amortized Inference with User Simulations
Abstract: There have been significant advances in simulation models predicting human behavior across various interactive tasks. One issue remains, however: identifying the parameter values that best describe an individual user. These parameters often express personal cognitive and physiological characteristics, and inferring their exact values has significant effects on individual-level predictions. Still, the high complexity of simulation models usually causes parameter inference to consume prohibitively large amounts of time, as much as days per user. We investigated amortized inference for its potential to reduce inference time dramatically, to mere tens of milliseconds. Its principle is to pre-train a neural proxy model for probabilistic inference, using synthetic data simulated from a range of parameter combinations. From examining the efficiency and prediction performance of amortized inference in three challenging cases that involve real-world data (menu search, point-and-click, and touchscreen typing), the paper demonstrates that an amortized-inference approach permits analyzing large-scale datasets by means of simulation models. It also addresses emerging opportunities and challenges in applying amortized inference in HCI.
URL: https://doi.org/10.1145/3544548.3581439

Title: Can a Computer Tell Differences between Vibrations?: Physiology-Based Computational Model for Perceptual Dissimilarity Prediction
Abstract: Perceptual dissimilarities, requiring high-cost user ratings, have contributed to designing well-distinguishable vibrations for associated meaning delivery. Appropriate metrics can reduce the cost, but known metrics in vibration similarity/dissimilarity could not predict them robustly. We propose a physiology-based model (PM) that predicts the perceptual dissimilarities of a given vibration set via two parallel processes: Neural Coding (NC), mimicking the neural signal transfer, and One-dimensional Convolution (OC), capturing rhythmic features. Eight parameters were trained using six datasets published in the literature to maximize Spearman’s Rank Correlation. We validated PM and six metrics of RMSE, DTW, Spectral/Temporal Matchings, ST-SIM, and SPQI in twelve datasets: six trained and six untrained datasets including measured accelerations. In all validations, PM’s predictions showed robust correlations with user data and similar structures in perceptual spaces. Other baseline metrics showed better fit in specific datasets, but none of them robustly showed correlations and similar perceptual spaces over twelve datasets.
URL: https://doi.org/10.1145/3544548.3580686

Title: Kaleidoscope: Semantically-Grounded, Context-Specific ML Model Evaluation
Abstract: Desired model behavior often differs across contexts (e.g., different geographies, communities, or institutions), but there is little infrastructure to facilitate context-specific evaluations key to deployment decisions and building trust. Here, we present Kaleidoscope, a system for evaluating models in terms of user-driven, domain-relevant concepts. Kaleidoscope’s iterative workflow enables generalizing from a few examples into a larger, diverse set representing an important concept. These example sets can be used to test model outputs or shifts in model behavior in semantically-meaningful ways. For instance, we might construct a “xenophobic comments” set and test that its examples are more likely to be flagged by a content moderation model than a “civil discussion” set. To evaluate Kaleidoscope, we compare it against template- and DSL-based grouping methods, and conduct a usability study with 13 Reddit users testing a content moderation model. We find that Kaleidoscope facilitates iterative, exploratory hypothesis testing across diverse, conceptually-meaningful example sets.
URL: https://doi.org/10.1145/3544548.3581482

Title: Sensorimotor Simulation of Redirected Reaching Using Stochastic Optimal Feedback Control
Abstract: Illusory VR interaction techniques such as hand redirection work because humans use vision to adjust their motor commands during movement (e.g., reaching). Existing simulations of redirected reaching are limited, however, and have not yet incorporated important stochastic characteristics like sensorimotor noise, nor captured redirection’s effect on movement duration. In this work, we propose adapting a stochastic optimal feedback control (SOFC) model of normal reach to simulate redirection by augmenting sensory feedback at run-time. We present a summary of our simulation and validate it against user data gathered in multiple redirection conditions. We also evaluate the impacts of visual attention on the effectiveness of redirection in real users and replicate the effects in simulation. Our results show that an infinite-horizon SOFC model is able to reproduce key characteristics of redirected reaches and highlight the benefits of SOFC as a tool for simulating, evaluating, and gaining insights about redirection techniques.
URL: https://doi.org/10.1145/3544548.3580767

Title: Shape-Adaptive Ternary-Gaussian Model: Modeling Pointing Uncertainty for Moving Targets of Arbitrary Shapes
Abstract: This paper presents a Shape-Adaptive Ternary-Gaussian model for describing endpoint uncertainty when pointing at moving targets of arbitrary shapes. The basic idea of the model is to combine the uncertainty related to the target shape with the uncertainty caused by the target motion. First, we proposed a model to predict endpoint distribution on static targets based on a Dual-Space Decomposition (DUDE) algorithm. Then, we linearly combined a 2D Ternary-Gaussian model with the newly proposed DUDE-based model to make the 2D Ternary-Gaussian model adaptable to moving targets with random shapes. To verify the performance of our model, we compared it with the original 2D Ternary-Gaussian model and a recent proposed Inscribed Circle model in predicting endpoint distribution. The results show that the proposed model outperformed the two baseline models while maintaining good robustness across different shapes and moving speeds.
URL: https://doi.org/10.1145/3544548.3581217